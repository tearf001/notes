#  基础

概率学中有许多基本公式，它们是理解和计算概率的基础。

## **1. 基本概率定义:**

* **事件 (Event):**  实验结果的集合。用大写字母表示，如 A, B, C。
* **样本空间 (Sample Space, Ω):** 所有可能实验结果的集合。
* **概率 (Probability):**  事件发生的可能性大小。用 P(A) 表示事件 A 发生的概率。

* **对于有限且`等可能`的结果：**
   P(A) = (事件 A 包含的结果数) / (样本空间 Ω 中包含的结果总数)

## **2. 事件的关系与运算:**

* **并集 (Union, ∪):** 事件 A 或事件 B 发生（或者都发生）。
    * **公式:** P(A ∪ B) = P(A) + P(B) - P(A ∩ B)
    * **解释:**  将 A 和 B 的概率加起来，然后减去重复的概率
* **交集 (Intersection, ∩):** 事件 A 和事件 B 同时发生。
    * **公式:** P(A ∩ B)
    * **解释:** 表示 A 和 B 同时发生的概率。文氏图:  A 和 B 重叠的区域。
* **互斥事件 (Mutually Exclusive Events):**  事件 A 和事件 B 不能同时发生。
    * **条件:** P(A ∩ B) = 0
    * **并集公式简化:**  如果 A 和 B 互斥，则 P(A ∪ B) = P(A) + P(B)
* **补集 (Complement, A' 或 A<sup>c</sup>):** 事件 A 不发生。
    * **公式:** P(A') = 1 - P(A)
* **差集 (Difference, A \ B 或 A - B):** 事件 A 发生但事件 B 不发生。
    * **公式:** P(A \ B) = P(A ∩ B') = P(A) - P(A ∩ B)
    * **解释:**  A 中去掉与 B 重叠的部分。

## **3. 条件概率:**

* **定义:** 在已知事件 B 发生的条件下，事件 A 发生的概率。
* **公式:** $P(A | B) = \frac{P(A ∩ B)} {P(B)}$ $※1$
* **解释:**  将*样本空间* **缩小**到事件 B 发生的范围内，计算 **A 在这个缩小空间中的概率**。

## **4. 独立性:**

* **独立事件 (Independent Events):** 事件 AB 的发生互不影响
* **条件:** $P(A ∩ B) = P(A) * P(B)$
  > 对于多个独立事件 A<sub>1</sub>, A<sub>2</sub>, ..., A<sub>n</sub>，同时发生的概率是各事件概率的乘积：P(A<sub>1</sub> ∩ A<sub>2</sub> ∩ ... ∩ A<sub>n</sub>) = P(A<sub>1</sub>) * P(A<sub>2</sub>) * ... * P(A<sub>n</sub>)
* 根据公式$※1$,  $P(A | B) = P(A); P(B | A) = P(B)$`

* **不独立事件 (Dependent Events):** 事件 A 的发生会影响事件 B 的发生，反之亦然。
    * **条件:** P(A ∩ B) ≠ P(A) * P(B)
    * **交集公式:**  对于不独立事件，计算交集需要使用条件概率：
        P(A ∩ B) = P(A | B) * P(B)  或者  P(A ∩ B) = P(B | A) * P(A)

## **5. 全概率公式:**

* **前提:** 假设事件 A<sub>1</sub>, A<sub>2</sub>, ..., A<sub>n</sub> 构成样本空间的一个划分 (Partition)，即它们两两互斥且它们的并集是整个样本空间 (A<sub>1</sub> ∪ A<sub>2</sub> ∪ ... ∪ A<sub>n</sub> = Ω)。
* **公式:** P(B) = P(B | A<sub>1</sub>)P(A<sub>1</sub>) + P(B | A<sub>2</sub>)P(A<sub>2</sub>) + ... + P(B | A<sub>n</sub>)P(A<sub>n</sub>) 
* **解释:** 分解为在不同划分A<sub>i</sub>事件条件下发生B的概率之和。

## **6. 贝叶斯公式 (Bayes' Theorem):**

* **公式:** $P(A_{i}| B) = \frac{P(B | A_{i})P(A_{i})} {P(B)}$
* **展开形式 (使用全概率公式替换 P(B)):**
    P(B) = $P(B | A_{1})P(A_{1}) + P(B | A_{2})P(A_{2}) + ... + P(B | A_{n})P(A_{n})$
* **解释:**  在已知事件 B 发生的情况下，推断导致 B 发生的某个原因 A<sub>i</sub> 的概率。贝叶斯公式常用于更新我们对事件概率的信念。

# 分布
二项式分布 binomial
- **概率质量函数 (PMF):**
    - P(X = k) = C(n, k) * p<sup>k</sup> * (1 - p)<sup>(n - k)</sup>
    - 其中：
        - n 是试验的总次数。
        - k 是成功的次数 (0 ≤ k ≤ n)。           
        - p 是单次试验成功的概率。
        - C(n, k) 是二项式系数，表示从 n 次试验中选择 k 次成功的组合数，计算公式为 $\frac{n!} {k!(n-k)!}$
## 连续分布
### PDF/CDF
### 高斯分布

# 贝叶斯统计
## 基础公式
假设是硬币
公平的情况 P(H) =.5
偏见`Biased` P(H) =.8
事件预测: A -> Y(H) {Y=.5 如果公平, Y=.8 如果偏见}
> P(Y =.5) = .75
> P(Y = .8) = .25

证据:
B -> X, X 是投掷的结果 0 , 1.

那么
$P_{Y|X=1}(.5)=\frac{P_{X|Y=.5}(1)*P_{Y}(.5)}{P_{X}(1)={P_{X|Y=.5}(1)*P_{Y}(.5)} + P_{Y}(.8) * P_{X|Y=.8}(1)}$

更普遍地,

$P_{Y|X=x}(y)= \frac{P_{X|Y=y}(x) \cdot P_{Y} (y)}{P_{X}(x)}$

还有一种写法:

${\displaystyle P_{\Theta | X=x}(\theta)_{\langle Posterior\rangle}={\frac {P_{X|\Theta=\theta}(x) \cdot P_{\Theta}(\theta)_{\langle Prior\rangle}}{P_{X}(x)}}}$简写为${\displaystyle p(\theta |x)={\frac {p(x|\theta )}{p(x)}}p(\theta )}$

|         | $\Theta$ 是离散的                                                                       | $\Theta$是连续的                                                                        |
| ------- | ----------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------- |
| $X$是离散的 | $P_{\Theta\|X=x}(\theta) = \frac{P_{X\|\Theta=\theta}(x) P_\Theta(\theta)}{P_X(x)}$ | $f_{\Theta\|X=x}(\theta) = \frac{P_{X\|\Theta=\theta}(x) f_\Theta(\theta)}{P_X(x)}$ |
| $X$是连续的 | $P_{\Theta\|X=x}(\theta) = \frac{f_{X\|\Theta=\theta}(x) P_\Theta(\theta)}{f_X(x)}$ | $f_{\Theta\|X=x}(\Theta) = \frac{f_{X\|\Theta=\Theta}(x) f_\Theta(\Theta)}{f_X(x)}$ |
伯努利:
$\Theta$ = P(H) 是连续变量
$X  = (X_{1}, X_{2}, ... X_{10})$ 伯努利自变量向量
$X_i | \Theta=\theta$ ~ 伯克利分布($\theta$)
那么求 后验 $f_{\Theta|X=x}(\theta)$

$f_{\Theta|X=x}(\theta) = \frac{P_{X|\Theta=\theta}(x) \cdot f_\Theta(\theta)}{P_X(x)}$
具体的例子
$P_{X|\Theta=\theta}(1,1,1,...1,0,0) = P(X_1=1, ....X_8=1,X_9=0,X_{10}=0 | \Theta)=\theta^8(1-\theta)^2$

现在求 在证据(1,1,1...1,0,0)情况下, $f_\Theta(\theta)=1$ 的概率密度函数($PDF$)
假设 $\Theta$ 是 $Uniform(0,1)$ 正态分布
$f_{\Theta|X=x}(\Theta)=\frac{\theta^8(1-\theta)^2\cdot1}{constant}$

$constant = P_{X|\Theta=\theta}(x_{111..00}) \cdot f_\Theta(\theta) + P_{X=x|\Theta}(!\theta) \cdot P_{}(!\theta)$